{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8cade1-5e82-4793-bf9b-b91ea45f07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afb2ca0-4a8e-4408-bf4e-c96e1bcd2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical file path: data_clinical_sample.txt\n",
      "Expression file path: data_mrna_seq_v2_rsem_zscores_ref_diploid_samples.txt\n"
     ]
    }
   ],
   "source": [
    "# Key file names\n",
    "clinical_file = \"data_clinical_sample.txt\"\n",
    "expression_file = \"data_mrna_seq_v2_rsem_zscores_ref_diploid_samples.txt\"\n",
    "\n",
    "print(f\"Clinical file path: {clinical_file}\")\n",
    "print(f\"Expression file path: {expression_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98001ea9-7b4e-4d74-9667-974bb9959b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of clinical data:\n",
      "     PATIENT_ID        SAMPLE_ID ONCOTREE_CODE    CANCER_TYPE  \\\n",
      "0  TCGA-3C-AAAU  TCGA-3C-AAAU-01           ILC  Breast Cancer   \n",
      "1  TCGA-3C-AALI  TCGA-3C-AALI-01           IDC  Breast Cancer   \n",
      "2  TCGA-3C-AALJ  TCGA-3C-AALJ-01           IDC  Breast Cancer   \n",
      "3  TCGA-3C-AALK  TCGA-3C-AALK-01           IDC  Breast Cancer   \n",
      "4  TCGA-4H-AAAK  TCGA-4H-AAAK-01           ILC  Breast Cancer   \n",
      "\n",
      "                CANCER_TYPE_DETAILED                      TUMOR_TYPE  GRADE  \\\n",
      "0  Breast Invasive Lobular Carcinoma  Infiltrating Lobular Carcinoma    NaN   \n",
      "1   Breast Invasive Ductal Carcinoma   Infiltrating Ductal Carcinoma    NaN   \n",
      "2   Breast Invasive Ductal Carcinoma   Infiltrating Ductal Carcinoma    NaN   \n",
      "3   Breast Invasive Ductal Carcinoma   Infiltrating Ductal Carcinoma    NaN   \n",
      "4  Breast Invasive Lobular Carcinoma  Infiltrating Lobular Carcinoma    NaN   \n",
      "\n",
      "  TISSUE_PROSPECTIVE_COLLECTION_INDICATOR  \\\n",
      "0                                      No   \n",
      "1                                      No   \n",
      "2                                      No   \n",
      "3                                      No   \n",
      "4                                     Yes   \n",
      "\n",
      "  TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR TISSUE_SOURCE_SITE_CODE  \\\n",
      "0                                       Yes                      3C   \n",
      "1                                       Yes                      3C   \n",
      "2                                       Yes                      3C   \n",
      "3                                       Yes                      3C   \n",
      "4                                        No                      4H   \n",
      "\n",
      "  TUMOR_TISSUE_SITE  ANEUPLOIDY_SCORE SAMPLE_TYPE  MSI_SCORE_MANTIS  \\\n",
      "0            Breast              19.0     Primary            0.3319   \n",
      "1            Breast              22.0     Primary            0.3449   \n",
      "2            Breast              13.0     Primary            0.3266   \n",
      "3            Breast               4.0     Primary            0.3218   \n",
      "4            Breast               7.0     Primary            0.3411   \n",
      "\n",
      "   MSI_SENSOR_SCORE SOMATIC_STATUS  TMB_NONSYNONYMOUS   TISSUE_SOURCE_SITE  \\\n",
      "0              0.55        Matched           0.800000  Columbia University   \n",
      "1              0.74        Matched          15.266667  Columbia University   \n",
      "2              0.31        Matched           0.933333  Columbia University   \n",
      "3              0.03        Matched           1.500000  Columbia University   \n",
      "4              0.01        Matched           0.700000    Proteogenex, Inc.   \n",
      "\n",
      "   TBL_SCORE  \n",
      "0      205.0  \n",
      "1      190.0  \n",
      "2      365.0  \n",
      "3       25.0  \n",
      "4       36.0  \n",
      "\n",
      "Clinical data dimensions: (1084, 19)\n",
      "\n",
      "Clinical data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1084 entries, 0 to 1083\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   PATIENT_ID                                 1084 non-null   object \n",
      " 1   SAMPLE_ID                                  1084 non-null   object \n",
      " 2   ONCOTREE_CODE                              1084 non-null   object \n",
      " 3   CANCER_TYPE                                1084 non-null   object \n",
      " 4   CANCER_TYPE_DETAILED                       1084 non-null   object \n",
      " 5   TUMOR_TYPE                                 1084 non-null   object \n",
      " 6   GRADE                                      0 non-null      float64\n",
      " 7   TISSUE_PROSPECTIVE_COLLECTION_INDICATOR    1080 non-null   object \n",
      " 8   TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR  1080 non-null   object \n",
      " 9   TISSUE_SOURCE_SITE_CODE                    1084 non-null   object \n",
      " 10  TUMOR_TISSUE_SITE                          1084 non-null   object \n",
      " 11  ANEUPLOIDY_SCORE                           1041 non-null   float64\n",
      " 12  SAMPLE_TYPE                                1084 non-null   object \n",
      " 13  MSI_SCORE_MANTIS                           1034 non-null   float64\n",
      " 14  MSI_SENSOR_SCORE                           1075 non-null   float64\n",
      " 15  SOMATIC_STATUS                             1084 non-null   object \n",
      " 16  TMB_NONSYNONYMOUS                          1066 non-null   float64\n",
      " 17  TISSUE_SOURCE_SITE                         1084 non-null   object \n",
      " 18  TBL_SCORE                                  1082 non-null   float64\n",
      "dtypes: float64(6), object(13)\n",
      "memory usage: 161.0+ KB\n"
     ]
    }
   ],
   "source": [
    "clinical_df = pd.read_csv(clinical_file, sep='\\t', comment='#')\n",
    "\n",
    "print(\"First rows of clinical data:\")\n",
    "print(clinical_df.head())\n",
    "\n",
    "# Show the dimensions (rows, columns)\n",
    "print(f\"\\nClinical data dimensions: {clinical_df.shape}\")\n",
    "\n",
    "# Show general information and data types\n",
    "print(\"\\nClinical data information:\")\n",
    "clinical_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8f7e78-7386-47a5-a470-c1cd03a11bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of expression data:\n",
      "  Hugo_Symbol  Entrez_Gene_Id  TCGA-3C-AAAU-01  TCGA-3C-AALI-01  \\\n",
      "0    UBE2Q2P2       100134869           0.9714           1.7813   \n",
      "1     HMGB1P1           10357              NaN              NaN   \n",
      "2   LOC155060          155060           5.1426           1.5334   \n",
      "3    RNU12-2P           26823              NaN              NaN   \n",
      "4        SSX9          280660          -0.0757           0.3125   \n",
      "\n",
      "   TCGA-3C-AALJ-01  TCGA-3C-AALK-01  TCGA-4H-AAAK-01  TCGA-5L-AAT0-01  \\\n",
      "0           0.2971           0.6341           1.2442           1.0947   \n",
      "1              NaN              NaN              NaN              NaN   \n",
      "2           1.9422           1.7309           0.1608           0.2438   \n",
      "3              NaN              NaN              NaN              NaN   \n",
      "4          -0.0757          -0.0757          -0.0757          -0.0757   \n",
      "\n",
      "   TCGA-5T-A9QA-01  TCGA-A1-A0SB-01  ...  TCGA-UL-AAZ6-01  TCGA-UU-A93S-01  \\\n",
      "0           0.2546           1.2376  ...           1.2337           0.5983   \n",
      "1              NaN              NaN  ...              NaN              NaN   \n",
      "2          -0.8316           0.2625  ...           0.1857          -0.2576   \n",
      "3              NaN              NaN  ...              NaN              NaN   \n",
      "4          -0.0757          -0.0757  ...           0.4942          -0.0757   \n",
      "\n",
      "   TCGA-V7-A7HQ-01  TCGA-W8-A86G-01  TCGA-WT-AB41-01  TCGA-WT-AB44-01  \\\n",
      "0          -0.8229           1.2335          -0.2347          -0.7904   \n",
      "1              NaN              NaN              NaN              NaN   \n",
      "2           2.1034           3.0236           0.2721           2.5474   \n",
      "3              NaN              NaN              NaN              NaN   \n",
      "4          -0.0757          -0.0757          -0.0757          -0.0757   \n",
      "\n",
      "   TCGA-XX-A899-01  TCGA-XX-A89A-01  TCGA-Z7-A8R5-01  TCGA-Z7-A8R6-01  \n",
      "0           2.5211           3.5835          -0.0555           3.1291  \n",
      "1              NaN              NaN              NaN              NaN  \n",
      "2           1.0554           0.7827           0.1135           0.0379  \n",
      "3              NaN              NaN              NaN              NaN  \n",
      "4          -0.0757          -0.0757          -0.0757          -0.0757  \n",
      "\n",
      "[5 rows x 1084 columns]\n",
      "\n",
      "Expression data dimensions: (20471, 1084)\n",
      "\n",
      "Expression data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20471 entries, 0 to 20470\n",
      "Columns: 1084 entries, Hugo_Symbol to TCGA-Z7-A8R6-01\n",
      "dtypes: float64(1082), int64(1), object(1)\n",
      "memory usage: 169.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load expression data\n",
    "expression_df = pd.read_csv(expression_file, sep='\\t', comment='#')\n",
    "\n",
    "print(\"First rows of expression data:\")\n",
    "print(expression_df.head())\n",
    "\n",
    "print(f\"\\nExpression data dimensions: {expression_df.shape}\")\n",
    "\n",
    "# Show general information \n",
    "print(\"\\nExpression data information:\")\n",
    "expression_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80641790-7077-4b0d-92ad-656d7bbaa9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of clinical_df set to 'SAMPLE_ID'.\n",
      "\n",
      "Distribution of subtypes in 'CANCER_TYPE_DETAILED':\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma            780\n",
      "Breast Invasive Lobular Carcinoma           201\n",
      "Breast Invasive Carcinoma (NOS)              77\n",
      "Breast Invasive Mixed Mucinous Carcinoma     17\n",
      "Metaplastic Breast Cancer                     8\n",
      "Invasive Breast Carcinoma                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Reduced clinical DataFrame (only with the subtype):\n",
      "                              CANCER_TYPE_DETAILED\n",
      "SAMPLE_ID                                         \n",
      "TCGA-3C-AAAU-01  Breast Invasive Lobular Carcinoma\n",
      "TCGA-3C-AALI-01   Breast Invasive Ductal Carcinoma\n",
      "TCGA-3C-AALJ-01   Breast Invasive Ductal Carcinoma\n",
      "TCGA-3C-AALK-01   Breast Invasive Ductal Carcinoma\n",
      "TCGA-4H-AAAK-01  Breast Invasive Lobular Carcinoma\n",
      "\n",
      "Clinical target dimensions: (1084, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Process Clinical Data ---\n",
    "\n",
    "# 1. Set SAMPLE_ID as index\n",
    "# Check if 'SAMPLE_ID' exists before trying to set it as index\n",
    "if 'SAMPLE_ID' in clinical_df.columns:\n",
    "    clinical_df.set_index('SAMPLE_ID', inplace=True)\n",
    "    print(\"Index of clinical_df set to 'SAMPLE_ID'.\")\n",
    "else:\n",
    "    print(\"Error: Column 'SAMPLE_ID' not found in clinical_df.\")\n",
    "\n",
    "# 2. Explore the subtype column \n",
    "subtype_column = 'CANCER_TYPE_DETAILED' # Check if this is the correct name in your output\n",
    "if subtype_column in clinical_df.columns:\n",
    "    print(f\"\\nDistribution of subtypes in '{subtype_column}':\")\n",
    "    print(clinical_df[subtype_column].value_counts())\n",
    "\n",
    "    # 3. Select only the subtype column\n",
    "    clinical_target = clinical_df[[subtype_column]].copy()\n",
    "    print(\"\\nReduced clinical DataFrame (only with the subtype):\")\n",
    "    print(clinical_target.head())\n",
    "    print(f\"\\nClinical target dimensions: {clinical_target.shape}\")\n",
    "else:\n",
    "    print(f\"\\nError: Column '{subtype_column}' not found. Check the column names in the previous output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc234c5d-64a7-482c-b877-93aaf21228f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of expression_df set to 'Hugo_Symbol'.\n",
      "Column 'Entrez_Gene_Id' removed.\n",
      "\n",
      "Warning! Found 41 duplicate gene names in the index.\n",
      "\n",
      "Transposed expression DataFrame (Samples x Genes):\n",
      "Hugo_Symbol      UBE2Q2P2  HMGB1P1  LOC155060  RNU12-2P    SSX9  EZHIP  \\\n",
      "TCGA-3C-AAAU-01    0.9714      NaN     5.1426       NaN -0.0757    NaN   \n",
      "TCGA-3C-AALI-01    1.7813      NaN     1.5334       NaN  0.3125    NaN   \n",
      "TCGA-3C-AALJ-01    0.2971      NaN     1.9422       NaN -0.0757    NaN   \n",
      "TCGA-3C-AALK-01    0.6341      NaN     1.7309       NaN -0.0757    NaN   \n",
      "TCGA-4H-AAAK-01    1.2442      NaN     0.1608       NaN -0.0757    NaN   \n",
      "\n",
      "Hugo_Symbol      EFCAB8  SRP14P1  LOC391343  TRIM75P  ...  ZWILCH   ZWINT  \\\n",
      "TCGA-3C-AAAU-01     NaN      NaN        NaN      NaN  ... -0.1901  0.2586   \n",
      "TCGA-3C-AALI-01     NaN      NaN        NaN      NaN  ...  3.8368  0.3218   \n",
      "TCGA-3C-AALJ-01     NaN      NaN        NaN      NaN  ... -0.7864  3.2995   \n",
      "TCGA-3C-AALK-01     NaN      NaN        NaN      NaN  ... -0.3052 -0.2421   \n",
      "TCGA-4H-AAAK-01     NaN      NaN        NaN      NaN  ... -0.2447 -0.2310   \n",
      "\n",
      "Hugo_Symbol        ZXDA    ZXDB    ZXDC  ZYG11A  ZYG11B     ZYX   ZZEF1  \\\n",
      "TCGA-3C-AAAU-01  2.5089  1.3913  2.4796  1.7214  1.1079 -0.1433  0.8874   \n",
      "TCGA-3C-AALI-01 -0.1717 -0.4056  1.0777  1.0692 -1.0514  0.9808 -0.3280   \n",
      "TCGA-3C-AALJ-01 -1.1112 -0.1312 -1.4752  2.5182 -1.3064  0.9550 -1.1205   \n",
      "TCGA-3C-AALK-01 -0.3556 -0.4406 -1.0526  0.8187 -1.0380  1.0859 -1.4616   \n",
      "TCGA-4H-AAAK-01 -0.5896 -0.4839 -0.2262 -0.9349 -0.4368  0.1575 -1.3545   \n",
      "\n",
      "Hugo_Symbol        ZZZ3  \n",
      "TCGA-3C-AAAU-01  0.3302  \n",
      "TCGA-3C-AALI-01 -1.1227  \n",
      "TCGA-3C-AALJ-01 -0.9297  \n",
      "TCGA-3C-AALK-01 -0.5704  \n",
      "TCGA-4H-AAAK-01 -0.2308  \n",
      "\n",
      "[5 rows x 20471 columns]\n",
      "\n",
      "Transposed dimensions: (1082, 20471)\n",
      "\n",
      "Total number of NaN values in expression data: 494474\n",
      "We will need to handle these NaNs in the next step.\n"
     ]
    }
   ],
   "source": [
    "# --- Process Expression Data ---\n",
    "\n",
    "# 1. Set Hugo_Symbol as index\n",
    "if 'Hugo_Symbol' in expression_df.columns:\n",
    "    expression_df.set_index('Hugo_Symbol', inplace=True)\n",
    "    print(\"Index of expression_df set to 'Hugo_Symbol'.\")\n",
    "\n",
    "    # 2. Remove Entrez_Gene_Id column\n",
    "    if 'Entrez_Gene_Id' in expression_df.columns:\n",
    "        expression_df.drop(columns=['Entrez_Gene_Id'], inplace=True)\n",
    "        print(\"Column 'Entrez_Gene_Id' removed.\")\n",
    "    else:\n",
    "        print(\"Warning: Column 'Entrez_Gene_Id' not found for removal.\")\n",
    "\n",
    "    # 3. Check for duplicates in the index\n",
    "    if expression_df.index.duplicated().any():\n",
    "        print(f\"\\nWarning! Found {expression_df.index.duplicated().sum()} duplicate gene names in the index.\")\n",
    "        # For now, just warn. We might need to handle them later.\n",
    "        # Optional: view duplicates: print(expression_df[expression_df.index.duplicated(keep=False)])\n",
    "    else:\n",
    "        print(\"\\nNo duplicate gene names found in the index.\")\n",
    "\n",
    "    # 4. Transpose the DataFrame \n",
    "    expression_df_T = expression_df.T\n",
    "    print(\"\\nTransposed expression DataFrame (Samples x Genes):\")\n",
    "    print(expression_df_T.head())\n",
    "    print(f\"\\nTransposed dimensions: {expression_df_T.shape}\") # Should be (1082, 20471)\n",
    "\n",
    "    # 5. Check for NaNs in the transposed DataFrame\n",
    "    nan_count = expression_df_T.isnull().sum().sum()\n",
    "    print(f\"\\nTotal number of NaN values in expression data: {nan_count}\")\n",
    "    if nan_count > 0:\n",
    "        print(\"We will need to handle these NaNs in the next step.\")\n",
    "\n",
    "else:\n",
    "    # This else corresponds to the initial check for 'Hugo_Symbol'\n",
    "    print(\"Error: Column 'Hugo_Symbol' not found in expression_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb942a4-6b60-4471-971d-67b29faf7017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common samples: 1082\n",
      "\n",
      "Aligned clinical dimensions: (1082, 1)\n",
      "Aligned expression dimensions: (1082, 20471)\n",
      "\n",
      "Success! The indices of both DataFrames now match.\n"
     ]
    }
   ],
   "source": [
    "# --- Align Samples ---\n",
    "\n",
    "# 1. Find the common indices (SAMPLE_ID)\n",
    "common_samples = clinical_target.index.intersection(expression_df_T.index)\n",
    "print(f\"Number of common samples: {len(common_samples)}\")\n",
    "\n",
    "# 2. Filter both DataFrames to keep only common samples and in the same order\n",
    "clinical_aligned = clinical_target.loc[common_samples]\n",
    "expression_aligned = expression_df_T.loc[common_samples]\n",
    "\n",
    "# 3. Verify the aligned dimensions\n",
    "print(f\"\\nAligned clinical dimensions: {clinical_aligned.shape}\")\n",
    "print(f\"Aligned expression dimensions: {expression_aligned.shape}\")\n",
    "\n",
    "# Verify that the indices are identical\n",
    "if clinical_aligned.index.equals(expression_aligned.index):\n",
    "    print(\"\\nSuccess! The indices of both DataFrames now match.\")\n",
    "else:\n",
    "    print(\"\\nError: Indices still do not match. Review previous steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f93379-1147-4ecc-b239-1b1499643e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate gene names found: ['PALM2AKAP2', 'NEBL', 'LCOR', 'CC2D2B', 'SPANXC', 'PLEKHG7', 'CDSN', 'MIA2', 'ELMOD1', 'QSOX1', 'FUT1', 'SNAP47', 'NKAIN3', 'PSMB5', 'TBXT']\n",
      "\n",
      "Number of gene columns removed due to duplicates: 2\n",
      "Expression dimensions after handling duplicates: (1082, 20460)\n",
      "Error: Duplicate genes still remain after handling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5794/3876591336.py:23: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  column_to_keep = mean_values.idxmax()\n",
      "/tmp/ipykernel_5794/3876591336.py:23: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  column_to_keep = mean_values.idxmax()\n"
     ]
    }
   ],
   "source": [
    "# --- Handle Duplicate Genes ---\n",
    "\n",
    "expression_no_duplicates = expression_aligned.copy()\n",
    "\n",
    "# Calculate the mean expression for each gene column\n",
    "gene_means = expression_no_duplicates.mean(axis=0) # axis=0 calculates the mean per column (gene)\n",
    "\n",
    "# Identify duplicate column names (genes)\n",
    "duplicated_genes = expression_no_duplicates.columns[expression_no_duplicates.columns.duplicated(keep=False)]\n",
    "# Only print if duplicates were actually found\n",
    "if not duplicated_genes.empty:\n",
    "    print(f\"\\nDuplicate gene names found: {duplicated_genes.unique().tolist()}\")\n",
    "\n",
    "genes_to_drop = []\n",
    "# Iterate over the unique gene names that had duplicates\n",
    "for gene in duplicated_genes.unique():\n",
    "    # Get the columns corresponding to this duplicate gene\n",
    "    duplicate_columns = expression_no_duplicates.columns[expression_no_duplicates.columns == gene]\n",
    "    # Find the mean expression for these specific duplicate columns\n",
    "    mean_values = gene_means[duplicate_columns]\n",
    "    # Identify the column (among duplicates for this gene) with the highest mean\n",
    "    column_to_keep = mean_values.idxmax()\n",
    "    # Mark the other duplicate columns (for this specific gene) for removal\n",
    "    columns_to_drop_for_gene = duplicate_columns.difference([column_to_keep])\n",
    "    genes_to_drop.extend(columns_to_drop_for_gene.tolist())\n",
    "\n",
    "# Only proceed if there are genes to drop\n",
    "if genes_to_drop:\n",
    "    # Remove the less informative duplicate columns\n",
    "    # Use .loc with boolean indexing to select columns to keep\n",
    "    # Keep columns NOT in genes_to_drop OR keep the first instance of any remaining duplicates (safety net)\n",
    "    expression_no_duplicates = expression_no_duplicates.loc[:, ~expression_no_duplicates.columns.isin(genes_to_drop) | ~expression_no_duplicates.columns.duplicated(keep='first')]\n",
    "\n",
    "    print(f\"\\nNumber of gene columns removed due to duplicates: {len(genes_to_drop)}\")\n",
    "else:\n",
    "    print(\"\\nNo duplicate gene columns needed removal based on mean expression.\")\n",
    "\n",
    "print(f\"Expression dimensions after handling duplicates: {expression_no_duplicates.shape}\") # Should have fewer or same columns as before\n",
    "\n",
    "# Check if duplicates still remain \n",
    "if not expression_no_duplicates.columns.duplicated().any():\n",
    "    print(\"Duplicate genes successfully handled (kept highest mean version).\")\n",
    "else:\n",
    "    print(\"Error: Duplicate genes still remain after handling.\")\n",
    "\n",
    "# Overwrite the aligned DataFrame with the version without duplicates (or the original if none were removed)\n",
    "expression_aligned = expression_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6d8b6f-ad46-4524-8a60-730cd1273f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of % NaNs per gene:\n",
      "count    20460.000000\n",
      "mean         2.179863\n",
      "std         14.602908\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max        100.000000\n",
      "dtype: float64\n",
      "\n",
      "Summary of % NaNs per sample:\n",
      "count    1.082000e+03\n",
      "mean     2.179863e+00\n",
      "std      3.110062e-15\n",
      "min      2.179863e+00\n",
      "25%      2.179863e+00\n",
      "50%      2.179863e+00\n",
      "75%      2.179863e+00\n",
      "max      2.179863e+00\n",
      "dtype: float64\n",
      "\n",
      "Genes with > 50% NaNs (446): ['HMGB1P1', 'RNU12-2P', 'EZHIP', 'EFCAB8', 'SRP14P1', 'LOC391343', 'TRIM75P', 'SPATA31B1P', 'REXO1L6P', 'LOC553137', 'HSPB1P1', 'PPBPP1', 'ANKRD20A20P', 'AMELY', 'BCORP1', 'BMS1P1', 'BPY2', 'LINC00596', 'C4orf50', 'CCL4L1', 'CD24', 'CDSN', 'CDY1', 'CDY1B', 'CDY2B', 'CSPG4P2Y', 'CT47A10', 'CT47A9', 'CTAG1B', 'CXorf49B', 'FAM226B', 'TXLNGY', 'DAD1P1', 'DAZ1', 'DAZ2', 'DAZ3', 'DAZ4', 'DDX3Y', 'DEFA1B', 'DEFB110', 'DEFB112', 'DEFB113', 'DEFB114', 'DEFB116', 'DEFB122', 'DEFB127', 'DEFB128', 'DEFB130A', 'PHF2P1', 'DMRTC1B', 'DUX4L1', 'EEF1A1P9', 'EIF1AY', 'FAM136BP', 'FAM138F', 'FAM197Y2', 'FAM41AY1', 'FAM45BP', 'CCNQP1', 'FAM74A4', 'ULK4P2', 'FER1L4', 'GDF1', 'GOLGA2P3Y', 'ADGRD2', 'GSX1', 'GTF2IRD2B', 'GTF2IRD2P1', 'SNORD115-24', 'SNORD115-27', 'SNORD115-28', 'SNORD115-45', 'SNORD115-47', 'HIST2H3C', 'FUT1', 'HSFY2', 'HSP90AB2P', 'HSP90B3P', 'ID2B', 'INTS4P1', 'ISCA1P1', 'KDM5D', 'KRTAP12-4', 'KRTAP13-3', 'KRTAP19-4', 'KRTAP19-7', 'KRTAP20-1', 'KRTAP20-3', 'KRTAP22-1', 'KRTAP23-1', 'LCE3B', 'BET1P1', 'SNRPGP15', 'LOC100132287', 'LOC100133331', 'NFE2L3P2', 'LOC143188', 'SEPHS1P1', 'ACTR2P2', 'H3F3AP5', 'LOC388955', 'PPIAP80', 'TUBBP6', 'BMS1P2', 'LOC646999', 'LRRC37A16P', 'DUX4L5', 'SPCS2P4', 'DUX4L2', 'GOLGA2P6', 'LYPLA2P1', 'MFRP', 'MORF4', 'MRGPRG', 'MSLNL', 'FAM223B', 'FAM224B', 'NLGN4Y', 'NME2P1', 'NXF2B', 'OR10J1', 'OR10K2', 'OR10T2', 'OR10X1', 'OR2T1', 'OR2T29', 'OR2T34', 'OR2T35', 'OR4F29', 'OR52A4P', 'OR6P1', 'OR9G9', 'PCDH11Y', 'PLA2G2E', 'PPIAL4C', 'PRAMEF14', 'PRINS', 'PRKY', 'PRO0611', 'PRO0628', 'PRR20A', 'PRR20B', 'PRR20D', 'PRY2', 'RBMY1A1', 'RBMY1A3P', 'RBMY1B', 'RBMY1E', 'RBMY1F', 'RBMY1J', 'RBMY2EP', 'RBMY2FP', 'RBMY3AP', 'REXO1L1P', 'RNF5P1', 'RNU5E-1', 'RNY4', 'RNY5', 'RPS4Y1', 'RPS4Y2', 'RSPH10B2', 'S100A7L2', 'SCARNA27', 'SNAR-A13', 'SNAR-A2', 'SNAR-A3', 'SNAR-A4', 'SNAR-B2', 'SNAR-C2', 'SNAR-C3', 'SNAR-D', 'SNAR-E', 'SNAR-G2', 'SNAR-H', 'SNORA11C', 'SNORA35', 'SNORA36B', 'SNORA36C', 'SNORA59B', 'SNORA70C', 'SNORD102', 'SNORD103A', 'SNORD104', 'SNORD105', 'SNORD105B', 'SNORD109B', 'SNORD110', 'SNORD111', 'SNORD111B', 'SNORD113-1', 'SNORD113-2', 'SNORD113-4', 'SNORD113-5', 'SNORD113-6', 'SNORD113-7', 'SNORD113-9', 'SNORD114-10', 'SNORD114-11', 'SNORD114-12', 'SNORD114-13', 'SNORD114-14', 'SNORD114-15', 'SNORD114-16', 'SNORD114-1', 'SNORD114-17', 'SNORD114-18', 'SNORD114-19', 'SNORD114-20', 'SNORD114-21', 'SNORD114-22', 'SNORD114-23', 'SNORD114-24', 'SNORD114-25', 'SNORD114-26', 'SNORD114-2', 'SNORD114-27', 'SNORD114-28', 'SNORD114-29', 'SNORD114-30', 'SNORD114-31', 'SNORD114-3', 'SNORD114-4', 'SNORD114-5', 'SNORD114-6', 'SNORD114-7', 'SNORD114-8', 'SNORD114-9', 'SNORD115-10', 'SNORD115-11', 'SNORD115-1', 'SNORD115-14', 'SNORD115-16', 'SNORD115-17', 'SNORD115-20', 'SNORD115-2', 'SNORD115-22', 'SNORD115-25', 'SNORD115-30', 'SNORD115-3', 'SNORD115-31', 'SNORD115-32', 'SNORD115-33', 'SNORD115-35', 'SNORD115-37', 'SNORD115-38', 'SNORD115-39', 'SNORD115-40', 'SNORD115-4', 'SNORD115-41', 'SNORD115-44', 'SNORD115-48', 'SNORD115-5', 'SNORD115-6', 'SNORD115-8', 'SNORD115-9', 'SNORD116-10', 'SNORD116-1', 'SNORD116-11', 'SNORD116-12', 'SNORD116-13', 'SNORD116-14', 'SNORD116-15', 'SNORD116-16', 'SNORD116-18', 'SNORD116-19', 'SNORD116-2', 'SNORD116-22', 'SNORD116-23', 'SNORD116-24', 'SNORD116-25', 'SNORD116-26', 'SNORD116-27', 'SNORD116-29', 'SNORD116-3', 'SNORD116-5', 'SNORD116-8', 'SNORD11', 'SNORD117', 'SNORD119', 'SNORD11B', 'SNORD121A', 'SNORD123', 'SNORD125', 'SNORD126', 'SNORD12', 'SNORD127', 'SNORD12B', 'SNORD12C', 'SNORD16', 'SNORD18A', 'SNORD18B', 'SNORD18C', 'SNORD19', 'SNORD19B', 'SNORD1A', 'SNORD1B', 'SNORD20', 'SNORD21', 'SNORD24', 'SNORD25', 'SNORD2', 'SNORD26', 'SNORD27', 'SNORD28', 'SNORD29', 'SNORD30', 'SNORD31', 'SNORD32A', 'SNORD32B', 'SNORD33', 'SNORD34', 'SNORD35A', 'SNORD35B', 'SNORD36A', 'SNORD36B', 'SNORD36C', 'SNORD37', 'SNORD38A', 'SNORD38B', 'SNORD41', 'SNORD42A', 'SNORD42B', 'SNORD43', 'SNORD44', 'SNORD45A', 'SNORD45B', 'SNORD45C', 'SNORD46', 'SNORD47', 'SNORD48', 'SNORD49A', 'SNORD49B', 'SNORD4A', 'SNORD4B', 'SNORD50A', 'SNORD50B', 'SNORD51', 'SNORD52', 'SNORD53', 'SNORD54', 'SNORD55', 'SNORD56', 'SNORD5', 'SNORD56B', 'SNORD57', 'SNORD58A', 'SNORD58C', 'SNORD59A', 'SNORD59B', 'SNORD60', 'SNORD61', 'SNORD62A', 'SNORD63', 'SNORD65', 'SNORD66', 'SNORD6', 'SNORD67', 'SNORD68', 'SNORD69', 'SNORD70', 'SNORD71', 'SNORD72', 'SNORD73A', 'SNORD74', 'SNORD75', 'SNORD76', 'SNORD7', 'SNORD77', 'SNORD78', 'SNORD79', 'SNORD80', 'SNORD81', 'SNORD82', 'SNORD84', 'SNORD103C', 'SNORD86', 'SNORD87', 'SNORD88A', 'SNORD88B', 'SNORD88C', 'SNORD90', 'SNORD91A', 'SNORD91B', 'SNORD92', 'SNORD93', 'SNORD95', 'SNORD9', 'SNORD96A', 'SNORD96B', 'SNORD98', 'SNORD99', 'SPINT4', 'SRY', 'TBXT', 'TBL1Y', 'TEX28', 'TGIF2LY', 'THSD1P1', 'TMSB4Y', 'TMSB4XP8', 'TREML5P', 'TRIM78P', 'TSPY1', 'TSPY2', 'TSPY3', 'TSPY4', 'TSSK2', 'TTLL8', 'TTTY10', 'TTTY11', 'TTTY12', 'TTTY13', 'TTTY14', 'TTTY15', 'TTTY16', 'TTTY17A', 'TTTY17B', 'TTTY18', 'TTTY19', 'TTTY1B', 'TTTY20', 'TTTY21', 'TTTY22', 'TTTY23', 'TTTY2', 'TTTY3B', 'TTTY4C', 'TTTY5', 'TTTY6', 'TTTY6B', 'TTTY7', 'TTTY8', 'TTTY9B', 'TUBB7P', 'TXNDC8', 'USP9Y', 'UTY', 'VCY', 'VTRNA1-1', 'VTRNA1-2', 'VTRNA1-3', 'WFDC9', 'XKRY2', 'XKRY', 'ZFY', 'ZNF322P1']\n",
      "\n",
      "No samples with > 50% NaNs.\n"
     ]
    }
   ],
   "source": [
    "# --- Check NaNs before Imputing ---\n",
    "\n",
    "# Calculate NaN percentage per gene (column)\n",
    "nan_percent_per_gene = expression_aligned.isnull().mean() * 100 # .mean() on booleans gives the proportion of True\n",
    "\n",
    "# Calculate NaN percentage per sample (row)\n",
    "nan_percent_per_sample = expression_aligned.isnull().mean(axis=1) * 100 # axis=1 for rows\n",
    "\n",
    "print(f\"\\nSummary of % NaNs per gene:\")\n",
    "print(nan_percent_per_gene.describe())\n",
    "\n",
    "print(f\"\\nSummary of % NaNs per sample:\")\n",
    "print(nan_percent_per_sample.describe())\n",
    "\n",
    "# Decide threshold (optional)\n",
    "threshold = 50\n",
    "genes_to_remove = nan_percent_per_gene[nan_percent_per_gene > threshold].index\n",
    "samples_to_remove = nan_percent_per_sample[nan_percent_per_sample > threshold].index\n",
    "\n",
    "# Check genes exceeding the threshold\n",
    "if not genes_to_remove.empty:\n",
    "    print(f\"\\nGenes with > {threshold}% NaNs ({len(genes_to_remove)}): {genes_to_remove.tolist()}\")\n",
    "    # Note: Actual removal is commented out by default\n",
    "    # expression_aligned.drop(columns=genes_to_remove, inplace=True) # Uncomment to remove\n",
    "else:\n",
    "    print(f\"\\nNo genes with > {threshold}% NaNs.\")\n",
    "\n",
    "# Check samples exceeding the threshold\n",
    "if not samples_to_remove.empty:\n",
    "    print(f\"\\nSamples with > {threshold}% NaNs ({len(samples_to_remove)}): {samples_to_remove.tolist()}\")\n",
    "    # Note: Actual removal is commented out by default\n",
    "    # expression_aligned.drop(index=samples_to_remove, inplace=True) # Uncomment to remove\n",
    "    # clinical_aligned = clinical_aligned.drop(index=samples_to_remove) # Important to align clinical data again if samples are removed!\n",
    "else:\n",
    "    print(f\"\\nNo samples with > {threshold}% NaNs.\")\n",
    "\n",
    "# Verify dimensions after removing (if uncommented above)\n",
    "# print(f\"\\nFinal dimensions before imputing: {expression_aligned.shape}\")\n",
    "# if 'clinical_aligned' in locals() and samples_to_remove.empty == False: # Check if clinical_aligned exists and samples were potentially removed\n",
    "#     print(f\"Clinical dimensions before imputing: {clinical_aligned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d99435a-666c-4cdf-b0b2-375112f36c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas ANTES de eliminar duplicados: 20460\n",
      "Hay duplicados ANTES: True\n",
      "\n",
      "Columnas DESPUÉS de eliminar duplicados: 20430\n",
      "Hay duplicados DESPUÉS: False\n"
     ]
    }
   ],
   "source": [
    "# ---  Remove Duplicates ---\n",
    "\n",
    "# Check duplicates BEFORE\n",
    "print(f\"Columns BEFORE removing duplicates: {expression_aligned.shape[1]}\")\n",
    "print(f\"Are there duplicates BEFORE: {expression_aligned.columns.duplicated().any()}\")\n",
    "\n",
    "# Remove duplicate columns, keeping the first occurrence\n",
    "# The selector `~expression_aligned.columns.duplicated(keep='first')` keeps columns that are not duplicates,\n",
    "# or if they are duplicates, it keeps only the first instance encountered.\n",
    "expression_no_duplicates_revised = expression_aligned.loc[:,~expression_aligned.columns.duplicated(keep='first')]\n",
    "\n",
    "# Check duplicates AFTER\n",
    "print(f\"\\nColumns AFTER removing duplicates: {expression_no_duplicates_revised.shape[1]}\")\n",
    "print(f\"Are there duplicates AFTER: {expression_no_duplicates_revised.columns.duplicated().any()}\") # This should now be False\n",
    "\n",
    "# Overwrite the DataFrame\n",
    "expression_aligned = expression_no_duplicates_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c75e43-56d6-4b1f-bec0-aa32812e2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes originally identified for removal (>50% NaN): 446\n",
      "Of those, 446 are present in the current DataFrame.\n",
      "\n",
      "Genes with > 50% NaNs removed.\n",
      "New expression dimensions: (1082, 20010)\n"
     ]
    }
   ],
   "source": [
    "# --- Remove Genes with > 50% NaNs ---\n",
    "\n",
    "print(f\"Number of genes originally identified for removal (>50% NaN): {len(genes_to_remove)}\")\n",
    "\n",
    "# Check how many of those genes are actually still present in the DataFrame's columns\n",
    "# (some might have been removed in previous steps, e.g., duplicate handling)\n",
    "cols_actually_in_df = genes_to_remove.intersection(expression_aligned.columns)\n",
    "print(f\"Of those, {len(cols_actually_in_df)} are present in the current DataFrame.\")\n",
    "\n",
    "# Proceed only if there are high-NaN genes still present to be removed\n",
    "if not cols_actually_in_df.empty:\n",
    "    # Remove the columns that both have >50% NaNs AND are still present\n",
    "    expression_aligned.drop(columns=cols_actually_in_df, inplace=True)\n",
    "    print(f\"\\nGenes with > 50% NaNs removed.\")\n",
    "    print(f\"New expression dimensions: {expression_aligned.shape}\")\n",
    "else:\n",
    "    # This happens if the genes identified previously were already removed (e.g., by duplicate removal)\n",
    "    print(\"\\nNo columns with > 50% NaNs found to remove (perhaps already removed during duplicate handling).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25897eb-ff5c-4fb4-b1f3-a77f177ba224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NaNs BEFORE imputing: 0\n",
      "\n",
      "No NaNs found to impute.\n",
      "\n",
      "Final expression dimensions (Samples x Genes): (1082, 20010)\n",
      "Final clinical dimensions (Samples x Target): (1082, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Impute NaNs with KNNImputer ---\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "print(f\"\\nNumber of NaNs BEFORE imputing: {expression_aligned.isnull().sum().sum()}\")\n",
    "\n",
    "if expression_aligned.isnull().sum().sum() > 0:\n",
    "    print(\"Starting KNN imputation (may take a few minutes)...\")\n",
    "\n",
    "    # Initialize the imputer\n",
    "    # n_neighbors=5 is a common value, you can adjust it if necessary\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Save column names and index before imputing, as KNNImputer returns a NumPy array\n",
    "    original_index = expression_aligned.index\n",
    "    original_columns = expression_aligned.columns\n",
    "\n",
    "    # Apply the imputer (fit and transform the data)\n",
    "    expression_imputed_array = imputer.fit_transform(expression_aligned)\n",
    "\n",
    "    # Convert the resulting NumPy array back to a pandas DataFrame\n",
    "    expression_imputed = pd.DataFrame(expression_imputed_array,\n",
    "                                      index=original_index,\n",
    "                                      columns=original_columns)\n",
    "\n",
    "    print(\"KNN imputation completed.\")\n",
    "    print(f\"Number of NaNs AFTER imputing: {expression_imputed.isnull().sum().sum()}\")\n",
    "\n",
    "    # Verify that there are no NaNs left after imputation\n",
    "    if expression_imputed.isnull().sum().sum() == 0:\n",
    "        print(\"Success! All NaNs have been imputed.\")\n",
    "        # Overwrite the aligned DataFrame with the imputed version for subsequent steps\n",
    "        expression_aligned = expression_imputed\n",
    "    else:\n",
    "        print(\"Error: NaNs still remain after imputation.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo NaNs found to impute.\")\n",
    "\n",
    "# Verify the final dimensions of both aligned dataframes to ensure they match on samples (rows)\n",
    "print(f\"\\nFinal expression dimensions (Samples x Genes): {expression_aligned.shape}\")\n",
    "print(f\"Final clinical dimensions (Samples x Target): {clinical_aligned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a88fe26-2195-42d7-a1cc-3b129464f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots will be saved to the 'images' directory.\n",
      "Scaling expression data...\n",
      "Scaling complete.\n",
      "\n",
      "Calculating PCA...\n",
      "PCA calculated.\n",
      "\n",
      "Variance explained by the first 10 PCs:\n",
      "[0.08340746 0.05566725 0.03901887 0.02309684 0.01872063 0.01645889\n",
      " 0.01271541 0.0119289  0.01048777 0.00893311]\n",
      "Total variance explained by the first 10 PCs: 0.28\n",
      "Generating PCA plot (saving to images/pca_plot.png)...\n",
      "PCA plot saved.\n",
      "\n",
      "Calculating UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puff/anaconda3/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP calculated.\n",
      "Generating UMAP plot (saving to images/umap_plot.png)...\n",
      "UMAP plot saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 12: EDA with Dimensionality Reduction ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import os # Import os module for directory creation\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = \"images\"\n",
    "os.makedirs(image_dir, exist_ok=True) \n",
    "print(f\"Plots will be saved to the '{image_dir}' directory.\")\n",
    "\n",
    "# 1. Scale the expression data (important for PCA/UMAP)\n",
    "# StandardScaler centers the data (mean=0) and scales to unit variance\n",
    "print(\"Scaling expression data...\")\n",
    "scaler = StandardScaler()\n",
    "# Assuming expression_aligned is Samples x Genes\n",
    "expression_scaled = scaler.fit_transform(expression_aligned)\n",
    "print(\"Scaling complete.\")\n",
    "\n",
    "# --- PCA ---\n",
    "print(\"\\nCalculating PCA...\")\n",
    "pca = PCA(n_components=10) # Calculate the first 10 components\n",
    "expression_pca = pca.fit_transform(expression_scaled)\n",
    "print(\"PCA calculated.\")\n",
    "\n",
    "# Create a DataFrame with PCA results and add the subtype\n",
    "pca_df = pd.DataFrame(data=expression_pca,\n",
    "                      columns=[f'PC{i+1}' for i in range(10)],\n",
    "                      index=expression_aligned.index) # Use the same index (SAMPLE_ID)\n",
    "# Join with the clinical subtype information\n",
    "# Ensure clinical_aligned has the SAMPLE_ID as index and contains subtype_column\n",
    "pca_df = pca_df.join(clinical_aligned)\n",
    "\n",
    "# Variance explained by each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"\\nVariance explained by the first 10 PCs:\")\n",
    "print(explained_variance_ratio)\n",
    "print(f\"Total variance explained by the first 10 PCs: {explained_variance_ratio.sum():.2f}\")\n",
    "\n",
    "# Visualize PC1 vs PC2\n",
    "print(f\"Generating PCA plot (saving to {image_dir}/pca_plot.png)...\")\n",
    "plt.figure(figsize=(12, 8)) # Adjusted size slightly for legend\n",
    "sns.scatterplot(\n",
    "    x=\"PC1\", y=\"PC2\",\n",
    "    hue=subtype_column, # Color by subtype\n",
    "    data=pca_df,\n",
    "    alpha=0.7, # Transparency\n",
    "    s=50 # Point size\n",
    ")\n",
    "plt.title('PCA of Gene Expression (PC1 vs PC2)')\n",
    "plt.xlabel(f'PC1 ({explained_variance_ratio[0]*100:.2f}% variance)') # Added \"variance\"\n",
    "plt.ylabel(f'PC2 ({explained_variance_ratio[1]*100:.2f}% variance)') \n",
    "plt.legend(title=subtype_column, bbox_to_anchor=(1.05, 1), loc='upper left') \n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "plt.savefig(os.path.join(image_dir, 'pca_plot.png'), bbox_inches='tight') \n",
    "plt.close() \n",
    "print(\"PCA plot saved.\")\n",
    "\n",
    "\n",
    "# --- UMAP --- \n",
    "print(\"\\nCalculating UMAP...\")\n",
    "# n_components=2 for 2D plot, random_state for reproducibility\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "expression_umap = reducer.fit_transform(expression_scaled) # Use scaled data\n",
    "print(\"UMAP calculated.\")\n",
    "\n",
    "# Create DataFrame for UMAP results\n",
    "umap_df = pd.DataFrame(data=expression_umap,\n",
    "                       columns=['UMAP1', 'UMAP2'],\n",
    "                       index=expression_aligned.index) # Use the same index\n",
    "# Join with the clinical subtype information\n",
    "umap_df = umap_df.join(clinical_aligned)\n",
    "\n",
    "# Visualize UMAP1 vs UMAP2\n",
    "print(f\"Generating UMAP plot (saving to {image_dir}/umap_plot.png)...\")\n",
    "plt.figure(figsize=(12, 8)) # Adjusted size slightly for legend\n",
    "sns.scatterplot(\n",
    "    x=\"UMAP1\", y=\"UMAP2\",\n",
    "    hue=subtype_column, # Color by subtype\n",
    "    data=umap_df,\n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "plt.title('UMAP of Gene Expression (UMAP1 vs UMAP2)')\n",
    "plt.xlabel('UMAP Component 1') \n",
    "plt.ylabel('UMAP Component 2') \n",
    "plt.legend(title=subtype_column, bbox_to_anchor=(1.05, 1), loc='upper left') \n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "plt.savefig(os.path.join(image_dir, 'umap_plot.png'), bbox_inches='tight') # Save the figure\n",
    "plt.close() \n",
    "print(\"UMAP plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4646a483-20bd-4a6c-a2d5-8c4d7fa21d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial X shape: (1082, 20010)\n",
      "Initial y shape: (1082,)\n",
      "Initial subtype distribution:\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma            780\n",
      "Breast Invasive Lobular Carcinoma           201\n",
      "Breast Invasive Carcinoma (NOS)              75\n",
      "Breast Invasive Mixed Mucinous Carcinoma     17\n",
      "Metaplastic Breast Cancer                     8\n",
      "Invasive Breast Carcinoma                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Checking for classes with < 2 members...\n",
      "Removing samples from classes with < 2 members: ['Invasive Breast Carcinoma']\n",
      "Samples removed. New dimensions:\n",
      "X shape: (1081, 20010)\n",
      "y shape: (1081,)\n",
      "\n",
      "New subtype distribution:\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma            780\n",
      "Breast Invasive Lobular Carcinoma           201\n",
      "Breast Invasive Carcinoma (NOS)              75\n",
      "Breast Invasive Mixed Mucinous Carcinoma     17\n",
      "Metaplastic Breast Cancer                     8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Checking for other minority classes to group...\n",
      "\n",
      "Grouping subtypes with < 25 samples into 'Other_Subtype': ['Breast Invasive Mixed Mucinous Carcinoma', 'Metaplastic Breast Cancer']\n",
      "\n",
      "Subtype distribution after grouping:\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma     780\n",
      "Breast Invasive Lobular Carcinoma    201\n",
      "Breast Invasive Carcinoma (NOS)       75\n",
      "Other_Subtype                         25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Splitting data into training and testing sets (70/30)...\n",
      "\n",
      "Data split into training and test sets:\n",
      "X_train shape: (756, 20010)\n",
      "X_test shape: (325, 20010)\n",
      "y_train shape: (756,)\n",
      "y_test shape: (325,)\n",
      "\n",
      "Subtype distribution in y_train (%):\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma     72.222222\n",
      "Breast Invasive Lobular Carcinoma    18.650794\n",
      "Breast Invasive Carcinoma (NOS)       6.878307\n",
      "Other_Subtype                         2.248677\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Subtype distribution in y_test (%):\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma     72.000000\n",
      "Breast Invasive Lobular Carcinoma    18.461538\n",
      "Breast Invasive Carcinoma (NOS)       7.076923\n",
      "Other_Subtype                         2.461538\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# --- Prepare Data for Modeling ---\n",
    "\n",
    "# 1. Define initial X (features) and y (target)\n",
    "X = expression_aligned # Our clean, aligned expression data (Samples x Genes)\n",
    "y = clinical_aligned[subtype_column] # Our subtype column (target)\n",
    "\n",
    "print(f\"Initial X shape: {X.shape}\")\n",
    "print(f\"Initial y shape: {y.shape}\")\n",
    "print(\"Initial subtype distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# 2. Identify and remove classes with fewer than 2 members (necessary for stratified split)\n",
    "print(\"\\nChecking for classes with < 2 members...\")\n",
    "counts = y.value_counts()\n",
    "classes_to_remove = counts[counts < 2].index\n",
    "\n",
    "if not classes_to_remove.empty:\n",
    "    print(f\"Removing samples from classes with < 2 members: {classes_to_remove.tolist()}\")\n",
    "    # Get the SAMPLE_IDs of the samples to remove\n",
    "    samples_to_remove_idx = y[y.isin(classes_to_remove)].index\n",
    "\n",
    "    # Remove the samples from both X and y\n",
    "    X = X.drop(index=samples_to_remove_idx)\n",
    "    y = y.drop(index=samples_to_remove_idx)\n",
    "\n",
    "    print(f\"Samples removed. New dimensions:\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(\"\\nNew subtype distribution:\")\n",
    "    print(y.value_counts())\n",
    "else:\n",
    "    print(\"No classes with fewer than 2 members found to remove.\")\n",
    "\n",
    "\n",
    "# --- GROUP OTHER MINORITY CLASSES ---\n",
    "# This step helps prevent small classes from dominating evaluation or causing issues\n",
    "print(\"\\nChecking for other minority classes to group...\")\n",
    "counts_after_removal = y.value_counts()\n",
    "# Define threshold: group classes with fewer than, e.g., 25 samples\n",
    "threshold_grouping = 25\n",
    "types_to_replace = counts_after_removal[counts_after_removal < threshold_grouping].index\n",
    "\n",
    "if not types_to_replace.empty:\n",
    "    print(f\"\\nGrouping subtypes with < {threshold_grouping} samples into 'Other_Subtype': {types_to_replace.tolist()}\")\n",
    "    # Replace these minority types with 'Other_Subtype' in the target variable y\n",
    "    y = y.replace(types_to_replace.tolist(), 'Other_Subtype')\n",
    "    print(\"\\nSubtype distribution after grouping:\")\n",
    "    print(y.value_counts())\n",
    "else:\n",
    "    print(f\"\\nNo additional minority subtypes (< {threshold_grouping} samples) found to group.\")\n",
    "# --- End of grouping ---\n",
    "\n",
    "# 3. Split into training and test sets \n",
    "print(\"\\nSplitting data into training and testing sets (70/30)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, # Use the potentially modified X and y\n",
    "    test_size=0.3,       # 30% for the test set\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y           # Ensure distribution of 'y' is similar in train/test\n",
    ")\n",
    "\n",
    "print(\"\\nData split into training and test sets:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nSubtype distribution in y_train (%):\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nSubtype distribution in y_test (%):\")\n",
    "print(y_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec636e4-d34d-4c53-bc79-0aee4f55a8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling training and testing data...\n",
      "Data scaled.\n",
      "X_train_scaled shape: (756, 20010)\n",
      "X_test_scaled shape: (325, 20010)\n"
     ]
    }
   ],
   "source": [
    "# --- Scale Features ---\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(\"Scaling training and testing data...\")\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "\n",
    "# Transform the test data using the scaler fitted on the training data\n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "print(\"Data scaled.\")\n",
    "# Note: The results (X_train_scaled, X_test_scaled) are NumPy arrays, not Pandas DataFrames\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe155a71-022c-4b55-b9bc-190ba4aec013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest model...\n",
      "Training completed.\n",
      "Making predictions on the test set...\n",
      "Evaluating model performance...\n",
      "\n",
      "Accuracy on the test set: 0.7938\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "  Breast Invasive Carcinoma (NOS)       0.00      0.00      0.00        23\n",
      " Breast Invasive Ductal Carcinoma       0.79      0.98      0.88       234\n",
      "Breast Invasive Lobular Carcinoma       0.82      0.47      0.60        60\n",
      "                    Other_Subtype       0.00      0.00      0.00         8\n",
      "\n",
      "                         accuracy                           0.79       325\n",
      "                        macro avg       0.40      0.36      0.37       325\n",
      "                     weighted avg       0.72      0.79      0.74       325\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  21   2   0]\n",
      " [  0 230   4   0]\n",
      " [  0  32  28   0]\n",
      " [  0   8   0   0]]\n",
      "Generating Confusion Matrix plot (saving to images/confusion_matrix_rf.png)...\n",
      "Confusion Matrix plot saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Evaluate RandomForest ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# 1. Initialize the RandomForest model\n",
    "# n_estimators=100 \n",
    "# random_state=42 \n",
    "# class_weight='balanced' can help with imbalanced classes (adjusts weights inversely proportional to class frequencies)\n",
    "# n_jobs=-1 uses all available CPU cores for training\n",
    "rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=42,\n",
    "                                class_weight='balanced',\n",
    "                                n_jobs=-1)\n",
    "\n",
    "# 2. Train the model with the scaled training data\n",
    "print(\"\\nTraining RandomForest model...\")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# 3. Predict the subtypes on the test set\n",
    "print(\"Making predictions on the test set...\")\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. Evaluate the performance\n",
    "print(\"Evaluating model performance...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy on the test set: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed Classification Report (precision, recall, f1-score per class)\n",
    "print(\"\\nClassification Report:\")\n",
    "# zero_division=0 prevents warnings if a class in y_true has no predictions (unlikely here but good practice)\n",
    "\n",
    "try:\n",
    "    # Get unique labels sorted \n",
    "    class_labels_sorted = sorted(y_test.unique())\n",
    "    report = classification_report(y_test, y_pred, zero_division=0, labels=class_labels_sorted)\n",
    "    print(report)\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate detailed report: {e}\")\n",
    "    # Fallback to basic report if labels cause issues\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_labels_sorted) # Ensure consistent label order\n",
    "print(cm) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "print(f\"Generating Confusion Matrix plot (saving to {image_dir}/confusion_matrix_rf.png)...\")\n",
    "plt.figure(figsize=(10, 8)) # Adjust size \n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels_sorted, yticklabels=class_labels_sorted)\n",
    "plt.xlabel('Predicted Label') \n",
    "plt.ylabel('True Label') \n",
    "plt.title('Confusion Matrix - RandomForest') \n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels if they overlap\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout() # Adjust layout\n",
    "plt.savefig(os.path.join(image_dir, 'confusion_matrix_rf.png'), bbox_inches='tight') \n",
    "plt.close() # Close the figure\n",
    "print(\"Confusion Matrix plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13654a42-c9cc-48a2-94f7-787f88ad067a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the top 1000 features using SelectKBest with f_classif...\n",
      "1000 genes were selected.\n",
      "\n",
      "New dimensions after selection:\n",
      "X_train_selected shape: (756, 1016)\n",
      "X_test_selected shape: (325, 1016)\n",
      "\n",
      "Re-scaling selected features...\n",
      "Re-scaling complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Selection ---\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# Number of features (genes) to select\n",
    "# We'll start with 1000\n",
    "k_best = 1000\n",
    "\n",
    "print(f\"Selecting the top {k_best} features using SelectKBest with f_classif...\")\n",
    "\n",
    "# Ensure X_train is the original DataFrame before scaling to get gene names\n",
    "# f_classif computes the ANOVA F-value between label/feature for classification tasks.\n",
    "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "\n",
    "# Fit the selector to the training data\n",
    "# We need y_train to calculate the feature association with the target\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the mask and names of the selected columns\n",
    "selected_cols_mask = selector.get_support()\n",
    "selected_genes = X_train.columns[selected_cols_mask]\n",
    "print(f\"{len(selected_genes)} genes were selected.\")\n",
    "\n",
    "# Filter original X_train and X_test DataFrames to keep only the selected features\n",
    "X_train_selected = X_train.loc[:, selected_genes]\n",
    "X_test_selected = X_test.loc[:, selected_genes]\n",
    "\n",
    "print(f\"\\nNew dimensions after selection:\")\n",
    "print(f\"X_train_selected shape: {X_train_selected.shape}\")\n",
    "print(f\"X_test_selected shape: {X_test_selected.shape}\")\n",
    "\n",
    "# --- RE-SCALE the selected data ---\n",
    "# Re-scale AFTER feature selection using only the selected features\n",
    "print(\"\\nRe-scaling selected features...\")\n",
    "scaler_selected = StandardScaler() # Initialize a new scaler instance\n",
    "\n",
    "# Fit the new scaler ONLY on the selected training data and transform it\n",
    "X_train_selected_scaled = scaler_selected.fit_transform(X_train_selected)\n",
    "\n",
    "# Transform the selected test data using the scaler fitted above\n",
    "X_test_selected_scaled = scaler_selected.transform(X_test_selected)\n",
    "print(\"Re-scaling complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5f44dc-c22d-46d9-adfa-ac2f3d264cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest model with selected features...\n",
      "Training completed.\n",
      "Making predictions on the test set using selected features...\n",
      "Evaluating model performance with selected features...\n",
      "\n",
      "Accuracy with selected features: 0.8031\n",
      "\n",
      "Classification Report (with selected features):\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "  Breast Invasive Carcinoma (NOS)       0.00      0.00      0.00        23\n",
      " Breast Invasive Ductal Carcinoma       0.81      0.97      0.88       234\n",
      "Breast Invasive Lobular Carcinoma       0.77      0.57      0.65        60\n",
      "                    Other_Subtype       0.00      0.00      0.00         8\n",
      "\n",
      "                         accuracy                           0.80       325\n",
      "                        macro avg       0.40      0.38      0.38       325\n",
      "                     weighted avg       0.72      0.80      0.76       325\n",
      "\n",
      "\n",
      "Confusion Matrix (with selected features):\n",
      "[[  0  20   3   0]\n",
      " [  0 227   7   0]\n",
      " [  0  26  34   0]\n",
      " [  0   8   0   0]]\n",
      "Generating Confusion Matrix plot (saving to images/confusion_matrix_rf_selected.png)...\n",
      "Confusion Matrix plot saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Re-train and Evaluate RandomForest (with selected features) ---\n",
    "\n",
    "# (The code is almost identical to the last cell, only the X input variables change)\n",
    "\n",
    "# 1. Initialize the RandomForest model \n",
    "rf_model_selected = RandomForestClassifier(n_estimators=100,\n",
    "                                         random_state=42,\n",
    "                                         class_weight='balanced',\n",
    "                                         n_jobs=-1)\n",
    "\n",
    "# 2. Train the model with the SELECTED and SCALED training data\n",
    "print(\"\\nTraining RandomForest model with selected features...\")\n",
    "rf_model_selected.fit(X_train_selected_scaled, y_train)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# 3. Predict on the SELECTED and SCALED test set\n",
    "print(\"Making predictions on the test set using selected features...\")\n",
    "# We use X_test_selected_scaled!!\n",
    "y_pred_selected = rf_model_selected.predict(X_test_selected_scaled)\n",
    "\n",
    "# 4. Evaluate the performance\n",
    "print(\"Evaluating model performance with selected features...\")\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "print(f\"\\nAccuracy with selected features: {accuracy_selected:.4f}\")\n",
    "\n",
    "# Detailed Classification Report\n",
    "print(\"\\nClassification Report (with selected features):\")\n",
    "# It's important to get the correct labels, especially if 'Other_Subtype' was created\n",
    "try:\n",
    "    class_labels_selected = sorted(y_test.unique())\n",
    "    report_selected = classification_report(y_test, y_pred_selected, zero_division=0, labels=class_labels_selected)\n",
    "    print(report_selected)\n",
    "except Exception as e:\n",
    "     print(f\"Could not generate detailed report: {e}\")\n",
    "     report_selected = classification_report(y_test, y_pred_selected, zero_division=0)\n",
    "     print(report_selected)\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (with selected features):\")\n",
    "# Ensure label order consistency\n",
    "cm_selected = confusion_matrix(y_test, y_pred_selected, labels=class_labels_selected)\n",
    "print(cm_selected) # Print raw matrix\n",
    "\n",
    "# Plot the confusion matrix\n",
    "print(f\"Generating Confusion Matrix plot (saving to {image_dir}/confusion_matrix_rf_selected.png)...\")\n",
    "plt.figure(figsize=(10, 8)) \n",
    "sns.heatmap(cm_selected, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels_selected, yticklabels=class_labels_selected)\n",
    "plt.xlabel('Predicted Label') \n",
    "plt.ylabel('True Label') \n",
    "plt.title('Confusion Matrix - RandomForest (Selected Features)') \n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout() \n",
    "plt.savefig(os.path.join(image_dir, 'confusion_matrix_rf_selected.png'), bbox_inches='tight')\n",
    "plt.close() \n",
    "print(\"Confusion Matrix plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6a89798-0c76-4a52-b59b-e60317d8614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to the training set...\n",
      "Class distribution BEFORE SMOTE:\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma     546\n",
      "Breast Invasive Lobular Carcinoma    141\n",
      "Breast Invasive Carcinoma (NOS)       52\n",
      "Other_Subtype                         17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SMOTE applied successfully.\n",
      "X_train shape AFTER SMOTE: (2184, 1016)\n",
      "Class distribution AFTER SMOTE:\n",
      "CANCER_TYPE_DETAILED\n",
      "Breast Invasive Ductal Carcinoma     546\n",
      "Breast Invasive Lobular Carcinoma    546\n",
      "Breast Invasive Carcinoma (NOS)      546\n",
      "Other_Subtype                        546\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training RandomForest model with SMOTE data...\n",
      "Training completed.\n",
      "Making predictions on the original test set...\n",
      "Evaluating model performance with SMOTE training data...\n",
      "\n",
      "Accuracy with SMOTE: 0.7908\n",
      "\n",
      "Classification Report (with SMOTE):\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "  Breast Invasive Carcinoma (NOS)       0.25      0.04      0.07        23\n",
      " Breast Invasive Ductal Carcinoma       0.84      0.89      0.87       234\n",
      "Breast Invasive Lobular Carcinoma       0.64      0.73      0.68        60\n",
      "                    Other_Subtype       0.75      0.38      0.50         8\n",
      "\n",
      "                         accuracy                           0.79       325\n",
      "                        macro avg       0.62      0.51      0.53       325\n",
      "                     weighted avg       0.76      0.79      0.77       325\n",
      "\n",
      "\n",
      "Confusion Matrix (with SMOTE):\n",
      "[[  1  18   4   0]\n",
      " [  3 209  21   1]\n",
      " [  0  16  44   0]\n",
      " [  0   5   0   3]]\n",
      "Generating Confusion Matrix plot (saving to images/confusion_matrix_rf_smote.png)...\n",
      "Confusion Matrix plot saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 18: Apply SMOTE and Re-train ---\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Initialize SMOTE\n",
    "# KNN = 5 \n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "print(\"\\nApplying SMOTE to the training set...\")\n",
    "# Check class distribution before applying SMOTE\n",
    "print(f\"Class distribution BEFORE SMOTE:\\n{pd.Series(y_train).value_counts()}\") # Ensure y_train is treated as Series for value_counts\n",
    "\n",
    "# 2. Apply SMOTE ONLY to the training data\n",
    "# SMOTE should not be applied to the test set\n",
    "# fit_resample returns the oversampled X and y data\n",
    "try:\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train_selected_scaled, y_train)\n",
    "    print(\"\\nSMOTE applied successfully.\")\n",
    "    print(f\"X_train shape AFTER SMOTE: {X_train_smote.shape}\") \n",
    "    print(f\"Class distribution AFTER SMOTE:\\n{pd.Series(y_train_smote).value_counts()}\") # All classes should have the same size (size of original majority class)\n",
    "\n",
    "    # 3. Initialize and Train RandomForest with SMOTE data\n",
    "    # (Using a new model variable name for clarity)\n",
    "    rf_model_smote = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "    print(\"\\nTraining RandomForest model with SMOTE data...\")\n",
    "    # Train using the SMOTE-resampled training data!\n",
    "    rf_model_smote.fit(X_train_smote, y_train_smote)\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    # 4. Predict on the ORIGINAL test set (selected and scaled, but NOT resampled)\n",
    "    print(\"Making predictions on the original test set...\")\n",
    "    # We use X_test_selected_scaled!! Test set should reflect real-world distribution.\n",
    "    y_pred_smote = rf_model_smote.predict(X_test_selected_scaled)\n",
    "\n",
    "    # 5. Evaluate the performance\n",
    "    print(\"Evaluating model performance with SMOTE training data...\")\n",
    "    accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "    print(f\"\\nAccuracy with SMOTE: {accuracy_smote:.4f}\")\n",
    "\n",
    "    # Detailed Classification Report\n",
    "    print(\"\\nClassification Report (with SMOTE):\")\n",
    "    # Get sorted unique labels from the original test set\n",
    "    class_labels_smote = sorted(pd.Series(y_test).unique())\n",
    "    try:\n",
    "        report_smote = classification_report(y_test, y_pred_smote, zero_division=0, labels=class_labels_smote)\n",
    "        print(report_smote)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate detailed report: {e}\")\n",
    "        report_smote = classification_report(y_test, y_pred_smote, zero_division=0)\n",
    "        print(report_smote)\n",
    "\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix (with SMOTE):\")\n",
    "    cm_smote = confusion_matrix(y_test, y_pred_smote, labels=class_labels_smote)\n",
    "    print(cm_smote) \n",
    "\n",
    "    print(f\"Generating Confusion Matrix plot (saving to {image_dir}/confusion_matrix_rf_smote.png)...\")\n",
    "    plt.figure(figsize=(10, 8)) \n",
    "    sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_labels_smote, yticklabels=class_labels_smote)\n",
    "    plt.xlabel('Predicted Label') \n",
    "    plt.ylabel('True Label') \n",
    "    plt.title('Confusion Matrix - RandomForest (SMOTE)') \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(os.path.join(image_dir, 'confusion_matrix_rf_smote.png'), bbox_inches='tight')\n",
    "    plt.close() \n",
    "    print(\"Confusion Matrix plot saved.\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"\\nSMOTE could not be applied. Error: {e}\")\n",
    "    print(\"This might happen if a class has fewer samples than k_neighbors (default 5).\")\n",
    "    print(\"Skipping SMOTE re-training and evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43b09f-703b-497d-abea-75478eddd014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
